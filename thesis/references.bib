@book{knuth1984,
  author    = {Donald E. Knuth},
  title     = {The \TeX book},
  year      = {1984},
  publisher = {Addison-Wesley},
  address   = {Reading, Massachusetts},
  series    = {Computers & Typesetting},
  volume    = {A},
  isbn      = {978-0-201-13448-7}
}

@article{einstein1905,
  author    = {Albert Einstein},
  title     = {Zur Elektrodynamik bewegter Körper},
  journal   = {Annalen der Physik},
  year      = {1905},
  volume    = {322},
  number    = {10},
  pages     = {891--921},
  doi       = {10.1002/andp.19053221004},
  language  = {german}
}

@inproceedings{turing1936,
  author    = {Alan M. Turing},
  title     = {On Computable Numbers, with an Application to the Entscheidungsproblem},
  booktitle = {Proceedings of the London Mathematical Society},
  year      = {1936},
  volume    = {2},
  number    = {42},
  pages     = {230--265},
  doi       = {10.1112/plms/s2-42.1.230}
}

@online{cern2025,
  author    = {CERN},
  title     = {The Large Hadron Collider},
  year      = {2025},
  url       = {https://home.cern/science/accelerators/large-hadron-collider},
  note      = {Accessed: 2025-05-10}
}

@thesis{smith2023,
  author    = {Emily Smith},
  title     = {Machine Learning Applications in Climate Science},
  year      = {2023},
  type      = {PhD thesis},
  institution = {Massachusetts Institute of Technology},
  address   = {Cambridge, MA}
}

@thesis{johnson2022,
  author    = {Michael Johnson},
  title     = {Data Visualization Techniques for Big Data},
  year      = {2022},
  type      = {Master's thesis},
  institution = {Stanford University},
  address   = {Stanford, CA}
}

@misc{nasa2024,
  author    = {NASA},
  title     = {Mars Exploration Program: Mission Overview},
  year      = {2024},
  howpublished = {\url{https://mars.nasa.gov/}},
  note      = {Accessed: 2025-05-10}
}

@article{author2019deep,
  author    = {J. K. Author},
  title     = {Deep learning for image recognition},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  volume    = {30},
  number    = {6},
  pages     = {1805--1815},
  year      = {2019},
  month     = {6}
}

@inproceedings{smith2021clustering,
  author    = {M. L. Smith and P. S. Kumar},
  title     = {A new approach to clustering in social networks},
  booktitle = {Proceedings of the IEEE International Conference on Big Data},
  address   = {Miami, FL, USA},
  year      = {2021},
  month     = {12},
  pages     = {45--50}
}

@book{author2018ml,
  author    = {A. N. Author},
  title     = {Introduction to Machine Learning},
  edition   = {2nd},
  publisher = {McGraw-Hill},
  address   = {New York, NY, USA},
  year      = {2018}
}

@misc{ieee2025style,
  author       = {{IEEE}},
  title        = {IEEE referencing style guide},
  howpublished = {\url{https://www.ieee.org/documents/ieee-style.pdf}},
  note         = {Accessed: Apr. 30, 2025}
}

@misc{stranas2020,
  author       = {{Kementerian Koordinator Bidang Perekonomian Republik Indonesia}},
  title        = {Strategi Nasional Kecerdasan Artifisial (Stranas KA) 2020--2045},
  year         = {2020},
  howpublished = {Online},
  note         = {Accessed: May 1, 2025},
  url          = {https://stranaska.id}
}

@misc{rpjmn2025,
  author       = {{Kementerian PPN/Bappenas}},
  title        = {Rencana Pembangunan Jangka Menengah Nasional (RPJMN) 2025--2029},
  year         = {2024},
  howpublished = {Online},
  note         = {Accessed: May 1, 2025},
  url          = {https://www.bappenas.go.id}
}

@misc{bps2024migration,
  author       = {{Badan Pusat Statistik}},
  title        = {International Migration Statistics at BPS-Statistics Indonesia},
  year         = {2024},
  howpublished = {\url{https://unstats.un.org/unsd/demographic-social/meetings/2024/migration-wk-poland-2024/Session13-Indonesia.pdf\break}},
  note         = {Accessed: 2025-05-01}
}

@book{oecd2022emigrants,
  author    = {{OECD}},
  title     = {A Review of Indonesian Emigrants},
  year      = {2022},
  series    = {Talent Abroad},
  publisher = {OECD Publishing},
  address   = {Paris},
  doi       = {10.1787/48a8a873-en},
  url       = {https://doi.org/10.1787/48a8a873-en},
  note      = {Accessed: 2025-05-01}
}

@misc{wikipedia2025overseas,
  author       = {{Wikipedia contributors}},
  title        = {Overseas Indonesians},
  year         = {2025},
  howpublished = {\url{https://en.wikipedia.org/wiki/Overseas_Indonesians}},
  note         = {Accessed: 2025-05-01}
}

@inproceedings{koto-etal-2020-indolem,
    title = "{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP}",
    author = "Koto, Fajri  and
      Rahimi, Afshin  and
      Lau, Jey Han  and
      Baldwin, Timothy",
    editor = "Scott, Donia  and
      Bel, Nuria  and
      Zong, Chengqing",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.66/",
    doi = "10.18653/v1/2020.coling-main.66",
    pages = "757--770",
    abstract = "Although the Indonesian language is spoken by almost 200 million people and the 10th most spoken language in the world, it is under-represented in NLP research. Previous work on Indonesian has been hampered by a lack of annotated datasets, a sparsity of language resources, and a lack of resource standardization. In this work, we release the IndoLEM dataset comprising seven tasks for the Indonesian language, spanning morpho-syntax, semantics, and discourse. We additionally release IndoBERT, a new pre-trained language model for Indonesian, and evaluate it over IndoLEM, in addition to benchmarking it against existing resources. Our experiments show that IndoBERT achieves state-of-the-art performance over most of the tasks in IndoLEM."
}

@inproceedings{koto-etal-2021-indobertweet,
    title = "{I}ndo{BERT}weet: A Pretrained Language Model for {I}ndonesian {T}witter with Effective Domain-Specific Vocabulary Initialization",
    author = "Koto, Fajri  and
      Lau, Jey Han  and
      Baldwin, Timothy",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.833/",
    doi = "10.18653/v1/2021.emnlp-main.833",
    pages = "10660--10668",
    abstract = "We present IndoBERTweet, the first large-scale pretrained model for Indonesian Twitter that is trained by extending a monolingually-trained Indonesian BERT model with additive domain-specific vocabulary. We focus in particular on efficient model adaptation under vocabulary mismatch, and benchmark different ways of initializing the BERT embedding layer for new word types. We find that initializing with the average BERT subword embedding makes pretraining five times faster, and is more effective than proposed methods for vocabulary adaptation in terms of extrinsic evaluation over seven Twitter-based datasets."
}

@inproceedings{devlin2019bert,
  author = {Jacob Devlin and 
    Ming-Wei Chang and 
    Kenton Lee and 
    Kristina Toutanova},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  booktitle = {Proceedings of NAACL-HLT},
  year = {2019},
  pages = {4171--4186}
}

@article{william2024emotion,
  title={Emotion recognition Indonesian language from Twitter using IndoBERT and Bi-LSTM},
  author={William, S. and Kenny and Chowanda, A.},
  journal={Communications in Mathematical Biology and Neuroscience},
  year={2024},
  number={71}
}

@article{kartika2023paraphrase,
  title={Fine-Tuned IndoBERT Based Model and Data Augmentation for Indonesian Language Paraphrase Identification},
  author={Kartika, Bagus V. and Alfredo, M. J. and Kusuma, G. P.},
  journal={Revue d'Intelligence Artificielle},
  volume={37},
  number={3},
  pages={217--224},
  year={2023},
  publisher={I2M}
}

@misc{indonlu2020,
  author       = {IndoNLP},
  title        = {IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},
  howpublished = {\url{https://github.com/IndoNLP/indonlu}},
  year         = 2020
}

@misc{hf_indobert_base,
  author       = {{Hugging Face}},
  title        = {indolem/indobert-base-uncased},
  howpublished = {\url{https://huggingface.co/indolem/indobert-base-uncased}},
  note         = {Accessed: 2025-05-02}
}

@misc{hf_sarahlintang,
  author       = {Hugging Face},
  title        = {sarahlintang/IndoBERT},
  howpublished = {\url{https://huggingface.co/sarahlintang/IndoBERT}},
  note         = {Accessed: 2025-05-02}
}

@misc{headfoundation2024,
  author       = {The HEAD Foundation},
  title        = {Unleashing the Potential of AI for Indonesia's Digital Government Transformation},
  year         = 2024,
  howpublished = {\url{https://digest.headfoundation.org/2024/07/10/unleashing-the-potential-of-ai-for-indonesias-digital-government-transformation/}}
}

@misc{reuters2025,
  author       = {Reuters},
  title        = {UK to explore use of Anthropic's AI chatbot Claude for public services},
  year         = 2025,
  howpublished = {\url{https://www.reuters.com/technology/artificial-intelligence/uk-explore-use-anthropics-ai-chatbot-claude-public-services-2025-02-14/}}
}

@misc{axios2024,
  author       = {Axios},
  title        = {Denver launches government info AI-powered chatbot},
  year         = 2024,
  howpublished = {\url{https://www.axios.com/local/denver/2024/04/25/denver-launches-ai-powered-chatbot-sunny}}
}

@article{unwomen2024,
  author = {UN Women},
  title = {Indonesia, UN Women launch AI chatbot ‘SARI’ to protect female migrant workers},
  journal = {Jakarta Daily},
  year = {2024},
  url = {https://www.jakartadaily.id/international/16214999370/indonesia-un-women-launch-ai-chatbot-sari-to-protect-female-migrant-workers}
}

@article{amiri2022,
  author = {A. Amiri, E. Henry, and L. Sahin},
  title = {Conversational AI for public service delivery: A systematic review},
  journal = {GovAI Working Paper},
  year = {2022}
}

@article{atallah2023,
  author = {N. Atallah},
  title = {Chatbots in consular affairs: Revolutionizing diplomacy or replacing empathy?},
  journal = {LinkedIn Pulse},
  year = {2023},
  url = {https://www.linkedin.com/pulse/chatbots-consular-affairs-revolutionising-diplomacy-n8gbe}
}


@article{koto2020,
  author = {F. Koto, A. Rahman, and M. Mahendra},
  title = {IndoBERT: A pre-trained language model for Indonesian},
  journal = {arXiv preprint arXiv:2011.00677},
  year = {2020}
}

@article{wilie2020,
  author = {B. Wilie et al.},
  title = {IndoNLU: Benchmark and resources for evaluating Indonesian natural language understanding},
  journal = {arXiv preprint arXiv:2009.05387},
  year = {2020}
}

@article{naufal2023,
  author = {M. Naufal},
  title = {Fine-tuning IndoBERT for Indonesian exam question classification based on Bloom’s taxonomy},
  journal = {ResearchGate},
  year = {2023},
  url = {https://www.researchgate.net/publication/375425989}
}

@misc{rizal2023,
  author = {M. Rizal},
  title = {Indobert-qa-finetuned-small-squad-indonesian-rizal},
  year = {2023},
  howpublished = {Hugging Face},
  url = {https://huggingface.co/mrizalf7/indobert-qa-finetuned-small-squad-indonesian-rizal}
}
