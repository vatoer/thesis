TY  - JOUR
AU  - Zhang, Gongbo
AU  - Xu, Zihan
AU  - Jin, Qiao
AU  - Chen, Fangyi
AU  - Fang, Yilu
AU  - Liu, Yi
AU  - Rousseau, Justin F.
AU  - Xu, Ziyang
AU  - Lu, Zhiyong
AU  - Weng, Chunhua
AU  - Peng, Yifan
PY  - 2025
DA  - 2025/05/02
TI  - Leveraging long context in retrieval augmented language models for medical question answering
JO  - npj Digital Medicine
SP  - 239
VL  - 8
IS  - 1
AB  - While holding great promise for improving and facilitating healthcare through applications of medical literature summarization, large language models (LLMs) struggle to produce up-to-date responses on evolving topics due to outdated knowledge or hallucination. Retrieval-augmented generation (RAG) is a pivotal innovation that improves the accuracy and relevance of LLM responses by integrating LLMs with a search engine and external sources of knowledge. However, the quality of RAG responses can be largely impacted by the rank and density of key information in the retrieval results, such as the “lost-in-the-middle” problem. In this work, we aim to improve the robustness and reliability of the RAG workflow in the medical domain. Specifically, we propose a map-reduce strategy, BriefContext, to combat the “lost-in-the-middle” issue without modifying the model weights. We demonstrated the advantage of the workflow with various LLM backbones and on multiple QA datasets. This method promises to improve the safety and reliability of LLMs deployed in healthcare domains by reducing the risk of misinformation, ensuring critical clinical content is retained in generated responses, and enabling more trustworthy use of LLMs in critical tasks such as medical question answering, clinical decision support, and patient-facing applications.
SN  - 2398-6352
UR  - https://doi.org/10.1038/s41746-025-01651-w
DO  - 10.1038/s41746-025-01651-w
ID  - Zhang2025
ER  - 
